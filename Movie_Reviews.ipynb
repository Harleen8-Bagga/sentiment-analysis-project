{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "484_ChXx99mG"
      },
      "source": [
        "# Sentiment analysis of movie reviews\n",
        "- In this notebook, **random forest classifier** model has been trained separately on **Bag of words** features and **word embeddings** to classify sentiment of movie reviews.\n",
        "- **Word2Vec** model to create **word embeddings** has been trained on sentiments using gensim library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOZvjLM9XWGr"
      },
      "source": [
        "## Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "PM4amHdEi4mE",
        "outputId": "d0b62375-bcb5-4eb6-8808-c78b6fcfed37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# downloads\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# sentence tokenizer\n",
        "from nltk.tokenize import sent_tokenize \n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "import logging\n",
        "from gensim.models import word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWiFrTR9Xb17"
      },
      "source": [
        "### Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS1GnND6B00A",
        "outputId": "2ce6f17f-2277-4a0e-8d55-396829e5d9cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsAZl8yZXgW8"
      },
      "source": [
        "## Extract data from zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "g2p8epei6EVs"
      },
      "outputs": [],
      "source": [
        "# zip file path  \n",
        "zip_data_path = '/content/drive/MyDrive/labeledTrainData.tsv.zip'\n",
        "\n",
        "# extract the contents of reviews.zip file\n",
        "extract_dir = '/tmp/'\n",
        "\n",
        "with ZipFile(zip_data_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwAx2WMR64bl",
        "outputId": "342defd7-e7b2-45a1-f096-6081b48bf8f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['initgoogle_syslog_dir.0',\n",
              " 'pyright-394-u0tybP8lQnVM',\n",
              " 'pyright-832-0S8vgIXIYiA5',\n",
              " 'dap_multiplexer.dfa107a60a97.root.log.INFO.20211230-014437.45',\n",
              " 'pyright-2063-ucZD3wE9ZsKU',\n",
              " 'directoryprefetcher_binary.dfa107a60a97.root.log.INFO.20211230-014552.249',\n",
              " 'pyright-97-rn6XICoIZe45',\n",
              " 'directoryprefetcher_binary.INFO',\n",
              " 'pyright-1710-a2yR4nI2n6Fs',\n",
              " 'pyright-1710-gfCcPBdfDqmc',\n",
              " 'pyright-97-zqRqnd5fOMnS',\n",
              " 'tmp0xmlmej6',\n",
              " 'python-languageserver-cancellation',\n",
              " 'pyright-323-l8GE47Y6rlcJ',\n",
              " 'labeledTrainData.tsv',\n",
              " 'pyright-323-lDLSoLqClzHn',\n",
              " 'debugger_7kstgqifd',\n",
              " 'pyright-2063-FtZ2B6Nd3NNx',\n",
              " 'drivefs_ipc.0',\n",
              " 'pyright-832-ELSCjHKjisqe',\n",
              " 'pyright-394-KxmUMfrF1J2k',\n",
              " 'drivefs_ipc.0_shell',\n",
              " 'dap_multiplexer.INFO']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "\n",
        "# list the contents of extract_dir\n",
        "os.listdir(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aTXFJVce7U_5",
        "outputId": "b5d55be2-4f80-4d1e-f671-600b1526b587"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0049b08e-914e-4386-8907-5b3505f5ad4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0049b08e-914e-4386-8907-5b3505f5ad4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0049b08e-914e-4386-8907-5b3505f5ad4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0049b08e-914e-4386-8907-5b3505f5ad4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# read the training data into pandas dataframe\n",
        "reviews_df = pd.read_csv(extract_dir + 'labeledTrainData.tsv', \n",
        "                         header = 0, \n",
        "                         delimiter = '\\t', \n",
        "                         quoting = 3)\n",
        "\n",
        "# display head of the dataframe\n",
        "reviews_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xjLYYMgYiHz"
      },
      "source": [
        "## Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylIy7Srq-Lur",
        "outputId": "5fd03ea7-02f1-421a-9111-8ca6f65fd5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   id         25000 non-null  object\n",
            " 1   sentiment  25000 non-null  int64 \n",
            " 2   review     25000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 586.1+ KB\n"
          ]
        }
      ],
      "source": [
        "reviews_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEWikgNH-cti",
        "outputId": "01bf1342-988f-40ba-e77f-3c5213bbcc88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Check the shape of the dataset\n",
        "reviews_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "mW7ntT1v-jTN",
        "outputId": "9334b4d8-d4c5-4209-de92-4dbb4dc1d7dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Check the number of reviews in each class\n",
        "reviews_df.sentiment.value_counts().plot(kind = 'bar');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4nfcNWc-vrw",
        "outputId": "98bdca76-193f-4375-9e64-ab0a7cadc9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of characters in reviews: 1329.71056\n"
          ]
        }
      ],
      "source": [
        "# Check the average number of characters\n",
        "print(f'Average number of characters in reviews: {np.mean(reviews_df.review.apply(len))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAdHVJuOZVlt"
      },
      "source": [
        "### Print first review from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Mhb1UBl-_qHI",
        "outputId": "dd5f5559-0386-40ae-c1bc-0cbb75cc7c86",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "reviews_df.review[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpzTB3TxZmBG"
      },
      "source": [
        "## Clean reviews by removing\n",
        "1. Slashes\n",
        "2. html tags\n",
        "3. Numbers\n",
        "4. Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "o1mRxrkY_jaL",
        "outputId": "db0fd9d5-5923-42cc-ab36-36cedf0a9a2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# remove html tags from first review\n",
        "review_1 = BeautifulSoup(reviews_df.review[0], features = 'lxml').text \n",
        "review_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_rxam48BtUL",
        "outputId": "90847b82-ba57-4054-ba64-a99721e7ccb0",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in first review: 15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again.',\n",
              " 'Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent.',\n",
              " 'Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released.',\n",
              " \"Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring.\",\n",
              " 'Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord.',\n",
              " 'Why he wants MJ dead so bad is beyond me.',\n",
              " 'Because MJ overheard his plans?',\n",
              " \"Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence.\",\n",
              " 'Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people).',\n",
              " 'If not, then stay away.',\n",
              " \"It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl!\",\n",
              " 'Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty?',\n",
              " \"Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact.\",\n",
              " 'He is either an extremely nice but stupid guy or one of the most sickest liars.',\n",
              " 'I hope he is not the latter.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# Tokenize the sentence\n",
        "print(f'Number of sentences in first review: {len(sent_tokenize(review_1))}')\n",
        "\n",
        "# doesn't really split all sentences\n",
        "sent_tokenize(review_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwanI5c-CPEN",
        "outputId": "9360cde6-4368-4100-b3a7-f9c8b91cb713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in first review: 23\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check if it does a better job if we add space after every period\n",
        "review_1 = review_1.replace('.','. ')\n",
        "\n",
        "print(f'Number of sentences in first review: {len(sent_tokenize(review_1))}', end = '\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHoMyLonb5fI"
      },
      "source": [
        "- It does solve the problem of splitting sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyhY3TJ2CqWL",
        "outputId": "18ac484b-5cd0-4ec5-d7a5-472b1a6a4926",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again.\n",
            "Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent.\n",
            "Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released.\n",
            "Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.\n",
            "Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring.\n",
            "Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.\n",
            "The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord.\n",
            "Why he wants MJ dead so bad is beyond me.\n",
            "Because MJ overheard his plans?\n",
            "Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.\n",
            "Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence.\n",
            "Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.\n",
            "Bottom line, this movie is for people who like MJ on one level or another (which i think is most people).\n",
            "If not, then stay away.\n",
            "It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl!\n",
            "Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty?\n",
            "Well, with all the attention i've gave this subject.\n",
            ".\n",
            ".\n",
            ".\n",
            "hmmm well i don't know because people can be different behind closed doors, i know this for a fact.\n",
            "He is either an extremely nice but stupid guy or one of the most sickest liars.\n",
            "I hope he is not the latter. \"\n"
          ]
        }
      ],
      "source": [
        "# print all sentences of first review\n",
        "for sentence in sent_tokenize(review_1):\n",
        "  print(sentence, end = '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "_sOaM2tOCy8O",
        "outputId": "b66b48c9-9400-49b2-9a61-e140c8b6b41c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'With all this stuff going down at the moment with MJ ive started listening to his music watching the odd documentary here and there watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJs feeling towards the press and also the obvious message of drugs are bad mkay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him The actual feature film bit when it finally starts is only on for  minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord  Why he wants MJ dead so bad is beyond me  Because MJ overheard his plans Nah Joe Pescis character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno maybe he just hates MJs music Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence  Also the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene Bottom line this movie is for people who like MJ on one level or another which i think is most people  If not then stay away  It does try and give off a wholesome message and ironically MJs bestest buddy in this movie is a girl Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty Well with all the attention ive gave this subject    hmmm well i dont know because people can be different behind closed doors i know this for a fact  He is either an extremely nice but stupid guy or one of the most sickest liars  I hope he is not the latter '"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "# remove punctuations and all special characters from first review\n",
        "review_1 = re.sub('[^a-zA-Z ]', '', review_1)\n",
        "review_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "2Ys6cfqRDLLK",
        "outputId": "5d138b76-9d6e-4630-a9e0-0dd64205b0cb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'with all this stuff going down at the moment with mj ive started listening to his music watching the odd documentary here and there watched the wiz and watched moonwalker again  maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  moonwalker is part biography part feature film which i remember going to see at the cinema when it was originally released  some of it has subtle messages about mjs feeling towards the press and also the obvious message of drugs are bad mkay visually impressive but of course this is all about michael jackson so unless you remotely like mj in anyway then you are going to hate this and find it boring  some may call mj an egotist for consenting to the making of this movie but mj and most of his fans would say that he made it for the fans which if true is really nice of him the actual feature film bit when it finally starts is only on for  minutes or so excluding the smooth criminal sequence and joe pesci is convincing as a psychopathic all powerful drug lord  why he wants mj dead so bad is beyond me  because mj overheard his plans nah joe pescis character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno maybe he just hates mjs music lots of cool things in this like mj turning into a car and a robot and the whole speed demon sequence  also the director must have had the patience of a saint when it came to filming the kiddy bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene bottom line this movie is for people who like mj on one level or another which i think is most people  if not then stay away  it does try and give off a wholesome message and ironically mjs bestest buddy in this movie is a girl michael jackson is truly one of the most talented people ever to grace this planet but is he guilty well with all the attention ive gave this subject    hmmm well i dont know because people can be different behind closed doors i know this for a fact  he is either an extremely nice but stupid guy or one of the most sickest liars  i hope he is not the latter '"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# lower case all the characters of the first review\n",
        "review_1 = review_1.lower()\n",
        "review_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GtMPaQicetN"
      },
      "source": [
        "### Define a helper function to clean all the reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "KeUH_BDTDT-N"
      },
      "outputs": [],
      "source": [
        "def clean_reviews(review):\n",
        "  \"\"\"\n",
        "  Clean and preprocess a review\n",
        "  1. Remove HTML tags\n",
        "  2. Use regex to remove all special characters (only keep letters)\n",
        "  3. Make strings to lower case and tokenize / word split reviews\n",
        "  4. Remove English stopwords\n",
        "  5. Rejoin to one string\n",
        "  \n",
        "  Args:\n",
        "      review: raw review\n",
        "  \n",
        "  Returns:\n",
        "      review: clean review\n",
        "  \"\"\"\n",
        "\n",
        "  #1. Remove HTML tags\n",
        "  review = BeautifulSoup(review).text\n",
        "  \n",
        "  #2. Use regex to find emoticons\n",
        "  emotions = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
        "  \n",
        "  #3. Remove punctuation\n",
        "  review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
        "  \n",
        "  #4. Tokenize into words (all lower case)\n",
        "  review = review.lower().split()\n",
        "  \n",
        "  #5. Remove stopwords\n",
        "  eng_stopwords = set(stopwords.words(\"english\"))\n",
        "  review = [w for w in review if not w in eng_stopwords]\n",
        "  \n",
        "  #6. Join the review to form one sentence\n",
        "  review = ' '.join(review + emotions)\n",
        "\n",
        "  return review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn4AFAabEQhs",
        "outputId": "a36e8f3a-be4e-4b99-b3b8-ac1c9b0a2def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with 5000 reviews\n",
            "Done with 10000 reviews\n",
            "Done with 15000 reviews\n",
            "Done with 20000 reviews\n",
            "Done with 25000 reviews\n"
          ]
        }
      ],
      "source": [
        "# store the clean reviews\n",
        "review_clean_original = []\n",
        "\n",
        "# number of reviews in the dataset\n",
        "num_reviews = reviews_df.shape[0]\n",
        "\n",
        "for i in range(num_reviews):\n",
        "  if((i + 1) % 5000 == 0 ):\n",
        "    # print progress\n",
        "    print(\"Done with %d reviews\" %(i + 1)) \n",
        "  review_clean_original.append(clean_reviews(reviews_df['review'][i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1tjq9nf5Vq"
      },
      "source": [
        "## Split the data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKsuBrX3ga3q",
        "outputId": "88778809-ff0f-4c44-be8f-924e26411a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (20000,)\n",
            "y_train shape: (20000,)\n",
            "x_val shape: (5000,)\n",
            "y_val shape: (5000,)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(np.array(review_clean_original), \n",
        "                                                  reviews_df['sentiment'], \n",
        "                                                  test_size = 0.2, \n",
        "                                                  random_state = 42, \n",
        "                                                  stratify = reviews_df['sentiment'])\n",
        "\n",
        "# print the shape of the training and validation datasets\n",
        "print(f'x_train shape: {x_train.shape}\\ny_train shape: {y_train.shape}')\n",
        "print(f'x_val shape: {x_val.shape}\\ny_val shape: {y_val.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnmkQse_99ml"
      },
      "source": [
        "## Bag of words approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6UPEnudhKFc",
        "outputId": "42c52500-f9fb-4936-f8e9-166e226b9546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(max_features=5000)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Instantiate CountVectorizer class object\n",
        "vectorizer = CountVectorizer(analyzer = \"word\", \n",
        "                             tokenizer = None, \n",
        "                             preprocessor = None, \n",
        "                             stop_words = None, \n",
        "                             max_features = 5000)\n",
        "\n",
        "# fit on the training data\n",
        "vectorizer.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aNIsdVniLTk",
        "outputId": "a5321caa-d75a-43ff-ee9d-c4117fe9c344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abandoned',\n",
              " 'abc',\n",
              " 'abilities',\n",
              " 'ability',\n",
              " 'able',\n",
              " 'abraham',\n",
              " 'absence',\n",
              " 'absent',\n",
              " 'absolute',\n",
              " 'absolutely']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# print the first 10 features\n",
        "vectorizer.get_feature_names()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-LA-SbpiTjK"
      },
      "outputs": [],
      "source": [
        "# Transform the training and validation data into a feature matrix\n",
        "train_bow = vectorizer.transform(x_train) \n",
        "val_bow = vectorizer.transform(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oDszYATnMhN",
        "outputId": "f97639b8-1299-4f71-cd71-ceb8c6ad7db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_bow shape: (20000, 5000)\n",
            "val_bow shape: (5000, 5000)\n"
          ]
        }
      ],
      "source": [
        "print(f'train_bow shape: {train_bow.toarray().shape}')\n",
        "print(f'val_bow shape: {val_bow.toarray().shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74FbERdWpal9"
      },
      "source": [
        "## Fit random forest classifier model on bag of words features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r82ED_bqnxXd",
        "outputId": "c7e8f4d9-edeb-4ec5-98d6-de010a6c3608"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Instantiate RandomForest Model\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf_model.fit(train_bow, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf0NTmZ9qHqV"
      },
      "source": [
        "## Evaluate the model performance on the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fh25fqAqM-3",
        "outputId": "fd2401a0-6ccf-4e18-970e-4b0129d7c5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation data set: 0.8472\n"
          ]
        }
      ],
      "source": [
        "pred_val = rf_model.predict(val_bow)\n",
        "print(f'Accuracy on validation data set: {accuracy_score(y_val, pred_val)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrRSE-Y-qfOP",
        "outputId": "3003e525-a63d-4191-cbb9-169940662bce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2134,  366],\n",
              "       [ 398, 2102]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# confusion matrix\n",
        "confusion_matrix(y_val, pred_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-FvdwsZqo2v",
        "outputId": "44961451-cf69-413c-9055-4624e90f19bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8462157809983897"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# f1-score\n",
        "f1_score(y_val, pred_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaYkC1aM99mp"
      },
      "source": [
        "## Define a function to prepare data, built and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSxx51IxyQct"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(cleaned_reviews, y = reviews_df[\"sentiment\"], max_features = 5000):\n",
        "  \"\"\"\n",
        "  This function prepares bag of words features, split the data into training and validation datasets,\n",
        "  fits the random forest model and evaluate its performance on the validation data\n",
        "  \n",
        "  Args:\n",
        "      cleaned_reviews: list of processed reviews\n",
        "      y: target variable (0: negative sentiment, 1: positive sentiment)\n",
        "      max_features: maximum number of words in the vocabulary\n",
        "      \n",
        "  Returns:\n",
        "      rf_model: random forest model\n",
        "      vectorizer: bag of words model\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  print(\"Creating the bag of words model!\\n\")\n",
        "  vectorizer = CountVectorizer(analyzer = \"word\",\n",
        "                               tokenizer = None,\n",
        "                               preprocessor = None,\n",
        "                               stop_words = None,\n",
        "                               max_features = max_features) \n",
        "    \n",
        "  print(\"Splitting data into training and validation sets!\\n\")\n",
        "  x_train, x_val, y_train, y_val = train_test_split(cleaned_reviews, \n",
        "                                                    y, \n",
        "                                                    random_state = 42, \n",
        "                                                    test_size = 0.2)\n",
        "\n",
        "  # use fit_transform() to fit the model/learn the vocabulary and transform the data into feature vectors\n",
        "  # input should be a list of strings. .toarraty() converts to a numpy array\n",
        "  \n",
        "  train_bow = vectorizer.fit_transform(x_train).toarray()\n",
        "  val_bow = vectorizer.transform(x_val).toarray()\n",
        "\n",
        "  # You can extract the vocabulary created by CountVectorizer\n",
        "  # by running print(vectorizer.get_feature_names())\n",
        "\n",
        "  print(\"Training the random forest classifier!\\n\")\n",
        "  # Initialize a Random Forest classifier\n",
        "  rf_model = RandomForestClassifier() \n",
        "\n",
        "  # Fit the random forest model to the training set, using the bag of words as \n",
        "  # features and the sentiment labels as the target variable\n",
        "  rf_model.fit(train_bow, y_train)\n",
        "\n",
        "\n",
        "  print(\"Making predictions on the validation set!\\n\")\n",
        "  val_preds = rf_model.predict(val_bow)\n",
        "\n",
        "  print(\"Calculating accuracy on the validation set!\\n\")\n",
        "  valid_acc = accuracy_score(y_val, val_preds)\n",
        "  print(\"The validation accuracy is: \", valid_acc)\n",
        "  \n",
        "  return (rf_model, vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model, vectorizer=predict_sentiment(review_clean_original, y = reviews_df[\"sentiment\"], max_features = 5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVL9repXjQKU",
        "outputId": "1ff48226-b6ef-461c-dafe-9617895c4097"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the bag of words model!\n",
            "\n",
            "Splitting data into training and validation sets!\n",
            "\n",
            "Training the random forest classifier!\n",
            "\n",
            "Making predictions on the validation set!\n",
            "\n",
            "Calculating accuracy on the validation set!\n",
            "\n",
            "The validation accuracy is:  0.8436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obMNUHAz99mq"
      },
      "source": [
        "## Prepare Word2Vec features using gensim library "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR6W26kSq0fO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4c8ba5-0b97-4fb8-e531-acc818e2ed60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-30 05:20:07,922 : INFO : collecting all words and their counts\n",
            "2021-12-30 05:20:07,924 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-30 05:20:08,234 : INFO : PROGRESS: at sentence #10000, processed 1205390 words, keeping 51389 word types\n",
            "2021-12-30 05:20:08,531 : INFO : PROGRESS: at sentence #20000, processed 2396959 words, keeping 67676 word types\n",
            "2021-12-30 05:20:08,684 : INFO : collected 74082 word types from a corpus of 2988534 raw words and 25000 sentences\n",
            "2021-12-30 05:20:08,686 : INFO : Loading a fresh vocabulary\n",
            "2021-12-30 05:20:08,758 : INFO : effective_min_count=40 retains 8164 unique words (11% of original 74082, drops 65918)\n",
            "2021-12-30 05:20:08,759 : INFO : effective_min_count=40 leaves 2627602 word corpus (87% of original 2988534, drops 360932)\n",
            "2021-12-30 05:20:08,792 : INFO : deleting the raw counts dictionary of 74082 items\n",
            "2021-12-30 05:20:08,797 : INFO : sample=0.001 downsamples 30 most-common words\n",
            "2021-12-30 05:20:08,798 : INFO : downsampling leaves estimated 2494733 word corpus (94.9% of prior 2627602)\n",
            "2021-12-30 05:20:08,835 : INFO : estimated required memory for 8164 words and 100 dimensions: 10613200 bytes\n",
            "2021-12-30 05:20:08,838 : INFO : resetting layer weights\n",
            "2021-12-30 05:20:10,591 : INFO : training model with 4 workers on 8164 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=12\n",
            "2021-12-30 05:20:11,621 : INFO : EPOCH 1 - PROGRESS: at 19.89% examples, 493189 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:12,649 : INFO : EPOCH 1 - PROGRESS: at 40.81% examples, 500471 words/s, in_qsize 8, out_qsize 0\n",
            "2021-12-30 05:20:13,667 : INFO : EPOCH 1 - PROGRESS: at 62.20% examples, 509554 words/s, in_qsize 6, out_qsize 1\n",
            "2021-12-30 05:20:14,671 : INFO : EPOCH 1 - PROGRESS: at 83.24% examples, 511990 words/s, in_qsize 6, out_qsize 1\n",
            "2021-12-30 05:20:15,375 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-12-30 05:20:15,395 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-12-30 05:20:15,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-12-30 05:20:15,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-12-30 05:20:15,410 : INFO : EPOCH - 1 : training on 2988534 raw words (2494420 effective words) took 4.8s, 518534 effective words/s\n",
            "2021-12-30 05:20:16,428 : INFO : EPOCH 2 - PROGRESS: at 19.89% examples, 500120 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:17,464 : INFO : EPOCH 2 - PROGRESS: at 41.44% examples, 510674 words/s, in_qsize 7, out_qsize 2\n",
            "2021-12-30 05:20:18,475 : INFO : EPOCH 2 - PROGRESS: at 62.94% examples, 517234 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:19,517 : INFO : EPOCH 2 - PROGRESS: at 84.88% examples, 519051 words/s, in_qsize 7, out_qsize 1\n",
            "2021-12-30 05:20:20,154 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-12-30 05:20:20,156 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-12-30 05:20:20,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-12-30 05:20:20,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-12-30 05:20:20,179 : INFO : EPOCH - 2 : training on 2988534 raw words (2494485 effective words) took 4.8s, 524271 effective words/s\n",
            "2021-12-30 05:20:21,197 : INFO : EPOCH 3 - PROGRESS: at 20.20% examples, 508268 words/s, in_qsize 6, out_qsize 1\n",
            "2021-12-30 05:20:22,219 : INFO : EPOCH 3 - PROGRESS: at 41.45% examples, 513543 words/s, in_qsize 6, out_qsize 1\n",
            "2021-12-30 05:20:23,245 : INFO : EPOCH 3 - PROGRESS: at 62.91% examples, 516800 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:24,250 : INFO : EPOCH 3 - PROGRESS: at 83.89% examples, 517452 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:24,966 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-12-30 05:20:24,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-12-30 05:20:24,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-12-30 05:20:24,996 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-12-30 05:20:24,997 : INFO : EPOCH - 3 : training on 2988534 raw words (2494572 effective words) took 4.8s, 518818 effective words/s\n",
            "2021-12-30 05:20:26,027 : INFO : EPOCH 4 - PROGRESS: at 20.21% examples, 501701 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:27,049 : INFO : EPOCH 4 - PROGRESS: at 41.78% examples, 514341 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:28,052 : INFO : EPOCH 4 - PROGRESS: at 62.94% examples, 518816 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:29,064 : INFO : EPOCH 4 - PROGRESS: at 84.22% examples, 519967 words/s, in_qsize 6, out_qsize 1\n",
            "2021-12-30 05:20:29,737 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-12-30 05:20:29,745 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-12-30 05:20:29,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-12-30 05:20:29,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-12-30 05:20:29,762 : INFO : EPOCH - 4 : training on 2988534 raw words (2494583 effective words) took 4.8s, 524580 effective words/s\n",
            "2021-12-30 05:20:30,769 : INFO : EPOCH 5 - PROGRESS: at 20.20% examples, 511844 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:31,772 : INFO : EPOCH 5 - PROGRESS: at 40.81% examples, 512042 words/s, in_qsize 8, out_qsize 2\n",
            "2021-12-30 05:20:32,774 : INFO : EPOCH 5 - PROGRESS: at 62.28% examples, 520151 words/s, in_qsize 7, out_qsize 0\n",
            "2021-12-30 05:20:33,791 : INFO : EPOCH 5 - PROGRESS: at 82.92% examples, 516275 words/s, in_qsize 6, out_qsize 1\n",
            "2021-12-30 05:20:34,535 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-12-30 05:20:34,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-12-30 05:20:34,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-12-30 05:20:34,574 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-12-30 05:20:34,576 : INFO : EPOCH - 5 : training on 2988534 raw words (2494988 effective words) took 4.8s, 519027 effective words/s\n",
            "2021-12-30 05:20:34,580 : INFO : training on a 14942670 raw words (12473048 effective words) took 24.0s, 519986 effective words/s\n",
            "2021-12-30 05:20:34,584 : INFO : precomputing L2-norms of word weight vectors\n",
            "2021-12-30 05:20:34,665 : INFO : saving Word2Vec object under 100features_40minwords_12context, separately None\n",
            "2021-12-30 05:20:34,671 : INFO : not storing attribute vectors_norm\n",
            "2021-12-30 05:20:34,673 : INFO : not storing attribute cum_table\n",
            "2021-12-30 05:20:34,761 : INFO : saved 100features_40minwords_12context\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 48.8 s, sys: 381 ms, total: 49.2 s\n",
            "Wall time: 27.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# configure the built-in logging module so that Word2Vec creates nice output messages\n",
        "logging.basicConfig(format = '%(asctime)s : %(levelname)s : %(message)s', \n",
        "                    level = logging.INFO)\n",
        "\n",
        "sentences = [review.split() for review in review_clean_original]\n",
        "\n",
        "# Set values for various parameters\n",
        "num_features = 100    # Word vector dimensionality                      \n",
        "min_word_count = 40   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 12          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "\n",
        "# Initialize and train the model (this will take some time)\n",
        "print(\"Training model...\")\n",
        "model = word2vec.Word2Vec(sentences, workers = num_workers, \n",
        "                          size = num_features, min_count = min_word_count,\n",
        "                          window = context, sample = downsampling)\n",
        "\n",
        "# If you don't plan to train the model any further, calling \n",
        "# init_sims will make the model much more memory-efficient.\n",
        "model.init_sims(replace = True)\n",
        "\n",
        "# It can be helpful to create a meaningful model name and \n",
        "# save the model for later use. You can load it later using Word2Vec.load()\n",
        "model_name = \"100features_40minwords_12context\"\n",
        "model.save(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyMcNL_Fs786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936b70f1-2bef-4b59-be70-3d15bb0774f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-30 05:20:38,934 : INFO : loading Word2Vec object from 100features_40minwords_12context\n",
            "2021-12-30 05:20:39,011 : INFO : loading wv recursively from 100features_40minwords_12context.wv.* with mmap=None\n",
            "2021-12-30 05:20:39,012 : INFO : setting ignored attribute vectors_norm to None\n",
            "2021-12-30 05:20:39,014 : INFO : loading vocabulary recursively from 100features_40minwords_12context.vocabulary.* with mmap=None\n",
            "2021-12-30 05:20:39,016 : INFO : loading trainables recursively from 100features_40minwords_12context.trainables.* with mmap=None\n",
            "2021-12-30 05:20:39,018 : INFO : setting ignored attribute cum_table to None\n",
            "2021-12-30 05:20:39,020 : INFO : loaded 100features_40minwords_12context\n"
          ]
        }
      ],
      "source": [
        "# load the word embeddings\n",
        "model = word2vec.Word2Vec.load(\"100features_40minwords_12context\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlbkpMjUvloS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49cd040-32b3-4c3a-fd42-eafdbed31741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8164, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# shape of the embedding matrix\n",
        "model.wv.vectors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57VR-gp1v7pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddf0726-13f3-4772-c38a-9a0f3c3a468d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab length: 8164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# Get vocabulary count of the model\n",
        "vocab_tmp = list(model.wv.vocab)\n",
        "print('Vocab length:', len(vocab_tmp))\n",
        "\n",
        "# Get distributional representation of each word\n",
        "X = model[vocab_tmp]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktd8RDPbw7JN"
      },
      "source": [
        "## Vector averaging to get the feature encoding of reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "973c0enNwcTg"
      },
      "outputs": [],
      "source": [
        "def makeFeatureVec(review, model):\n",
        "  \"\"\"\n",
        "  This function returns the average of word vectors in a given review\n",
        "  \n",
        "  Args:\n",
        "      review: a single movie review\n",
        "      model: Word2Vec model\n",
        "\n",
        "  Returns:\n",
        "      featureVec: average of word vectors in a given review\n",
        "  \"\"\"\n",
        "  # Function to average all of the word vectors in a given paragraph\n",
        "  featureVec = []\n",
        "  \n",
        "  # Index2word is a list that contains the names of the words in \n",
        "  # the model's vocabulary. Convert it to a set, for speed \n",
        "  index2word_set = set(model.wv.index2word)\n",
        "  \n",
        "  # Loop over each word in the review and, if it is in the model's\n",
        "  # vocaublary, add its feature vector to the total\n",
        "  for n, word in enumerate(review):\n",
        "    if word in index2word_set: \n",
        "      featureVec.append(model[word])\n",
        "          \n",
        "  # Average the word vectors for a review\n",
        "  featureVec = np.mean(featureVec, axis = 0)\n",
        "  return featureVec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA0tBDM099mt"
      },
      "outputs": [],
      "source": [
        "def getAvgFeatureVecs(reviews, model):\n",
        "  \"\"\"\n",
        "  This function calculates the average feature vector for each review\n",
        "  \n",
        "  Args:\n",
        "      reviews: list of reviews\n",
        "      model: Word2Vec model\n",
        "      \n",
        "  Returns:\n",
        "      reviewFeatureVecs: average of feature vectors for all the reviews\n",
        "  \"\"\"\n",
        "  # Given a set of reviews (each one a list of words), calculate \n",
        "  # the average feature vector for each review\n",
        "  \n",
        "  reviewFeatureVecs = []\n",
        "  # Loop through the reviews\n",
        "  for counter, review in enumerate(reviews):\n",
        "    # Print a status message every 5000th review\n",
        "    if counter % 5000. == 0.:\n",
        "      print(\"Review %d of %d\" % (counter, len(reviews)))\n",
        "\n",
        "    # Call the function (defined above) that makes average feature vectors\n",
        "    vector = makeFeatureVec(review, model)\n",
        "    reviewFeatureVecs.append(vector)\n",
        "        \n",
        "  return reviewFeatureVecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x52DukvByGVC"
      },
      "outputs": [],
      "source": [
        "def train_sentiment(cleaned_reviews, y = reviews_df[\"sentiment\"]):\n",
        "  \"\"\"\n",
        "  This function will:\n",
        "  1. Convert reviews into feature vectors using word2vec.\n",
        "  2. split data into train and validation set.\n",
        "  3. train a random forest model using word embeddings and y (labels)\n",
        "  4. validate the model on the validation split\n",
        "  5. print accuracy of sentiment prediction on validation data\n",
        "  6. print confusion matrix on validation data results\n",
        "  \n",
        "  Args:\n",
        "      cleaned_reviews: list of processed reviews\n",
        "      y: target variable (0: negative sentiment, 1: positive sentiment)\n",
        "      \n",
        "  Returns: None  \n",
        "  \"\"\"\n",
        "\n",
        "  print(\"1.Creating Feature vectors using word2vec...\\n\")\n",
        "  trainDataVecs = getAvgFeatureVecs(cleaned_reviews, model)\n",
        "  \n",
        "  \n",
        "  print(\"\\n2.Splitting dataset into train and test sets...\\n\")\n",
        "  x_train, x_val, y_train, y_val = train_test_split(trainDataVecs, y, random_state = 42, test_size = 0.2)\n",
        "\n",
        "  \n",
        "  print(\"3. Training the random forest classifier...\\n\")\n",
        "  # Initialize Random Forest classifier \n",
        "  rf_model = RandomForestClassifier() \n",
        "\n",
        "  # Fit the random forest model to the training set, using word embeddings as\n",
        "  # features and the sentiment labels as the target variable\n",
        "  rf_model.fit(train_bow, y_train)\n",
        "  \n",
        "  print(\"Making predictions on the validation set!\\n\")\n",
        "  val_preds = rf_model.predict(val_bow)\n",
        "\n",
        "  print(\"Calculating accuracy on the validation set!\\n\")\n",
        "  valid_acc = accuracy_score(y_val, val_preds)\n",
        "  print(\"The validation accuracy is: \", valid_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvFsJCH200hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b39e54a-464b-4846-9168-98eb29b5f2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.Creating Feature vectors using word2vec...\n",
            "\n",
            "Review 0 of 25000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review 5000 of 25000\n",
            "Review 10000 of 25000\n",
            "Review 15000 of 25000\n",
            "Review 20000 of 25000\n",
            "\n",
            "2.Splitting dataset into train and test sets...\n",
            "\n",
            "3. Training the random forest classifier...\n",
            "\n",
            "Making predictions on the validation set!\n",
            "\n",
            "Calculating accuracy on the validation set!\n",
            "\n",
            "The validation accuracy is:  0.5022\n"
          ]
        }
      ],
      "source": [
        "train_sentiment(cleaned_reviews = review_clean_original, y = reviews_df[\"sentiment\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LQ2Yl3M99mu"
      },
      "source": [
        "- The validation accuracy of random forest classifier trained on word embeddings is very low. This is due to small size of dataset to train word embeddings from scratch. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model to disk\n",
        "import pickle\n",
        "pickle.dump(rf_model, open('model.pkl','wb'))"
      ],
      "metadata": {
        "id": "DmcwMkAezTnK"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(vectorizer, open('vectorizer.pkl','wb'))\n"
      ],
      "metadata": {
        "id": "Qi1_MTzP8go1"
      },
      "execution_count": 101,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of Movie_Reviews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}